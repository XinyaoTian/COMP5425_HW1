{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 â€“ Document Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to complete a program to find similar documents (e.g., articles, queries or questions in sentence) for a given query (e.g., an article or a sentence). The similarity can be defined by you, such as content similarity or emotion similarity such as sentiment. You can use the 20 Newsgroup dataset or any similar dataset you can find.\n",
    "20 Newsgroup Dataset:\n",
    "https://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (3 marks) Use tf-idf based document representation for the task. \n",
    "\n",
    "You can use existing\n",
    "third-party libraries for document pre-processing (e.g., tokenization), however, you need to write your own code to derive tf-idf representation and compute similarity between two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1:\n",
      "This is an txt file used for practicing Python.\n",
      "The second line.\n",
      "Hello, world! --  This is the third line.\n",
      "The End. -- This is the bottom line.\n"
     ]
    }
   ],
   "source": [
    "# Read the first file\n",
    "text_file = open(\"./sample_files/textScript1.txt\", \"r\")\n",
    "text_content1 = text_file.read()\n",
    "text_file.close()\n",
    "# check the first 200 characters\n",
    "print(text_content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2: \n",
      "You are required to complete a program to find similar documents (e.g., articles, queries or questions in sentence) for a given query (e.g., an article or a sentence). \n",
      "The similarity can be defined by you, such as content similarity or emotion similarity such as sentiment. \n",
      "You can use the 20 Newsgroup dataset or any similar dataset you can find.\n"
     ]
    }
   ],
   "source": [
    "# Read the second file\n",
    "text_file = open(\"./sample_files/textScript2.txt\", \"r\")\n",
    "text_content2 = text_file.read()\n",
    "text_file.close()\n",
    "# check the first 200 characters\n",
    "print(text_content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/xinyaotian/anaconda3/lib/python3.7/site-packages (3.3)\r\n",
      "Requirement already satisfied: six in /Users/xinyaotian/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install tokenize function\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def calTermFrequency(text_content):\n",
    "    tknzr = TweetTokenizer()\n",
    "    tokenized_list = tknzr.tokenize(text_content)\n",
    "    \n",
    "    # Calculate term frequency\n",
    "    term_frequency_dict = dict()\n",
    "    for term in tokenized_list:\n",
    "        if term in term_frequency_dict.keys():\n",
    "            term_frequency_dict[term] += 1\n",
    "        else:\n",
    "            term_frequency_dict[term] = 1\n",
    "    \n",
    "    # Conduct Log operation for each term\n",
    "    log_tf_dict = dict()\n",
    "    for term in term_frequency_dict:\n",
    "        log_tf_dict[term] = (1 + log(term_frequency_dict[term], 10))\n",
    "        \n",
    "    return log_tf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLogTermFrequencyList():\n",
    "    # Need further Calsupalate of reading text_content1\n",
    "    log_tf_1 = calTermFrequency(text_content1)\n",
    "    log_tf_2 = calTermFrequency(text_content2)\n",
    "    logged_tf_list = list()\n",
    "    logged_tf_list.append(log_tf_1)\n",
    "    logged_tf_list.append(log_tf_2)\n",
    "    return logged_tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_tf_list = generateLogTermFrequencyList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'File': 1.0,\n",
       "  '1': 1.0,\n",
       "  ':': 1.0,\n",
       "  'This': 1.4771212547196624,\n",
       "  'is': 1.4771212547196624,\n",
       "  'an': 1.0,\n",
       "  'txt': 1.0,\n",
       "  'file': 1.0,\n",
       "  'used': 1.0,\n",
       "  'for': 1.0,\n",
       "  'practicing': 1.0,\n",
       "  'Python': 1.0,\n",
       "  '.': 1.6989700043360187,\n",
       "  'The': 1.3010299956639813,\n",
       "  'second': 1.0,\n",
       "  'line': 1.4771212547196624,\n",
       "  'Hello': 1.0,\n",
       "  ',': 1.0,\n",
       "  'world': 1.0,\n",
       "  '!': 1.0,\n",
       "  '-': 1.6020599913279623,\n",
       "  'the': 1.3010299956639813,\n",
       "  'third': 1.0,\n",
       "  'End': 1.0,\n",
       "  'bottom': 1.0},\n",
       " {'File': 1.0,\n",
       "  '2': 1.0,\n",
       "  ':': 1.0,\n",
       "  'You': 1.3010299956639813,\n",
       "  'are': 1.0,\n",
       "  'required': 1.0,\n",
       "  'to': 1.3010299956639813,\n",
       "  'complete': 1.0,\n",
       "  'a': 1.4771212547196624,\n",
       "  'program': 1.0,\n",
       "  'find': 1.3010299956639813,\n",
       "  'similar': 1.3010299956639813,\n",
       "  'documents': 1.0,\n",
       "  '(': 1.3010299956639813,\n",
       "  'e': 1.3010299956639813,\n",
       "  '.': 1.8450980400142567,\n",
       "  'g': 1.3010299956639813,\n",
       "  ',': 1.6020599913279623,\n",
       "  'articles': 1.0,\n",
       "  'queries': 1.0,\n",
       "  'or': 1.6020599913279623,\n",
       "  'questions': 1.0,\n",
       "  'in': 1.0,\n",
       "  'sentence': 1.3010299956639813,\n",
       "  ')': 1.3010299956639813,\n",
       "  'for': 1.0,\n",
       "  'given': 1.0,\n",
       "  'query': 1.0,\n",
       "  'an': 1.0,\n",
       "  'article': 1.0,\n",
       "  'The': 1.0,\n",
       "  'similarity': 1.4771212547196624,\n",
       "  'can': 1.4771212547196624,\n",
       "  'be': 1.0,\n",
       "  'defined': 1.0,\n",
       "  'by': 1.0,\n",
       "  'you': 1.3010299956639813,\n",
       "  'such': 1.3010299956639813,\n",
       "  'as': 1.3010299956639813,\n",
       "  'content': 1.0,\n",
       "  'emotion': 1.0,\n",
       "  'sentiment': 1.0,\n",
       "  'use': 1.0,\n",
       "  'the': 1.0,\n",
       "  '20': 1.0,\n",
       "  'Newsgroup': 1.0,\n",
       "  'dataset': 1.3010299956639813,\n",
       "  'any': 1.0}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_tf_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list that contains all terms appearing among all document\n",
    "def generateOverallTermList(logged_tf_list):\n",
    "    all_term_list = list()\n",
    "    for tf_dict in logged_tf_list:\n",
    "        for term in tf_dict:\n",
    "            if term in all_term_list:\n",
    "                pass\n",
    "            else:\n",
    "                all_term_list.append(term)\n",
    "    \n",
    "    return all_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_term_list = generateOverallTermList(logged_tf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeightMatrix(logged_tf_list, all_term_list):\n",
    "    # Initiate a empty dictionary in order to save a Word Vector of each document\n",
    "    weight_matrix_dict = dict()\n",
    "    count = 0\n",
    "    # For every document which exists in the record list\n",
    "    for file_dict in logged_tf_list:\n",
    "        word_exist_list = list()\n",
    "        # Nominate the document name\n",
    "        filename = \"Filename_\" + str(count)\n",
    "        count += 1\n",
    "        # For each word in the overall word list, \n",
    "        for word in all_term_list:\n",
    "            # if it exsits in this document, then set the value to 1\n",
    "            if word in file_dict:\n",
    "                word_exist_list.append(1)\n",
    "            # otherwise, set the value to 0, indicating that this word doesn't appear in this Doc\n",
    "            else:\n",
    "                word_exist_list.append(0)\n",
    "        \n",
    "        # Add the Word Vector of this document to the general dict\n",
    "        # In order to form a BIG 2x2 Table\n",
    "        weight_matrix_dict[filename] = word_exist_list\n",
    "    \n",
    "    return weight_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_dict = generateWeightMatrix(logged_tf_list, all_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename_0</th>\n",
       "      <th>Filename_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename_0  Filename_1\n",
       "0            1           1\n",
       "1            1           0\n",
       "2            1           1\n",
       "3            1           0\n",
       "4            1           0\n",
       "5            1           1\n",
       "6            1           0\n",
       "7            1           0\n",
       "8            1           0\n",
       "9            1           1\n",
       "10           1           0\n",
       "11           1           0\n",
       "12           1           1\n",
       "13           1           1\n",
       "14           1           0\n",
       "15           1           0\n",
       "16           1           0\n",
       "17           1           1\n",
       "18           1           0\n",
       "19           1           0\n",
       "20           1           0\n",
       "21           1           1\n",
       "22           1           0\n",
       "23           1           0\n",
       "24           1           0\n",
       "25           0           1\n",
       "26           0           1\n",
       "27           0           1\n",
       "28           0           1\n",
       "29           0           1\n",
       "..         ...         ...\n",
       "35           0           1\n",
       "36           0           1\n",
       "37           0           1\n",
       "38           0           1\n",
       "39           0           1\n",
       "40           0           1\n",
       "41           0           1\n",
       "42           0           1\n",
       "43           0           1\n",
       "44           0           1\n",
       "45           0           1\n",
       "46           0           1\n",
       "47           0           1\n",
       "48           0           1\n",
       "49           0           1\n",
       "50           0           1\n",
       "51           0           1\n",
       "52           0           1\n",
       "53           0           1\n",
       "54           0           1\n",
       "55           0           1\n",
       "56           0           1\n",
       "57           0           1\n",
       "58           0           1\n",
       "59           0           1\n",
       "60           0           1\n",
       "61           0           1\n",
       "62           0           1\n",
       "63           0           1\n",
       "64           0           1\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weightMatrix = pd.DataFrame(wm_dict)\n",
    "weightMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['File',\n",
       " '1',\n",
       " ':',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'txt',\n",
       " 'file',\n",
       " 'used',\n",
       " 'for',\n",
       " 'practicing',\n",
       " 'Python',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'line',\n",
       " '.',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'world',\n",
       " '!',\n",
       " '-',\n",
       " '-',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " '.',\n",
       " 'The',\n",
       " 'End',\n",
       " '.',\n",
       " '-',\n",
       " '-',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'line',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "term_tokenize = tknzr.tokenize(text_content1)\n",
    "term_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File': 1,\n",
       " '1': 1,\n",
       " ':': 1,\n",
       " 'This': 3,\n",
       " 'is': 3,\n",
       " 'an': 1,\n",
       " 'txt': 1,\n",
       " 'file': 1,\n",
       " 'used': 1,\n",
       " 'for': 1,\n",
       " 'practicing': 1,\n",
       " 'Python': 1,\n",
       " '.': 5,\n",
       " 'The': 2,\n",
       " 'second': 1,\n",
       " 'line': 3,\n",
       " 'Hello': 1,\n",
       " ',': 1,\n",
       " 'world': 1,\n",
       " '!': 1,\n",
       " '-': 4,\n",
       " 'the': 2,\n",
       " 'third': 1,\n",
       " 'End': 1,\n",
       " 'bottom': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency1 = dict()\n",
    "for word in term_tokenize:\n",
    "    if word in term_frequency1.keys():\n",
    "        term_frequency1[word] += 1\n",
    "    else:\n",
    "        term_frequency1[word] = 1\n",
    "\n",
    "term_frequency1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File': 1.0,\n",
       " '1': 1.0,\n",
       " ':': 1.0,\n",
       " 'This': 1.4771212547196624,\n",
       " 'is': 1.4771212547196624,\n",
       " 'an': 1.0,\n",
       " 'txt': 1.0,\n",
       " 'file': 1.0,\n",
       " 'used': 1.0,\n",
       " 'for': 1.0,\n",
       " 'practicing': 1.0,\n",
       " 'Python': 1.0,\n",
       " '.': 1.6989700043360187,\n",
       " 'The': 1.3010299956639813,\n",
       " 'second': 1.0,\n",
       " 'line': 1.4771212547196624,\n",
       " 'Hello': 1.0,\n",
       " ',': 1.0,\n",
       " 'world': 1.0,\n",
       " '!': 1.0,\n",
       " '-': 1.6020599913279623,\n",
       " 'the': 1.3010299956639813,\n",
       " 'third': 1.0,\n",
       " 'End': 1.0,\n",
       " 'bottom': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "log_tf1 = dict()\n",
    "\n",
    "for key in term_frequency1:\n",
    "    log_tf1[key] = log(term_frequency1[key], 10) + 1\n",
    "    \n",
    "log_tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (2 marks) Improve the tf-idf based method or design a better method for improved retrieval performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
