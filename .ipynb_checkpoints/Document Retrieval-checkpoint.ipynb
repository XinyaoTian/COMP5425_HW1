{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1 â€“ Document Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to complete a program to find similar documents (e.g., articles, queries or questions in sentence) for a given query (e.g., an article or a sentence). The similarity can be defined by you, such as content similarity or emotion similarity such as sentiment. You can use the 20 Newsgroup dataset or any similar dataset you can find.\n",
    "20 Newsgroup Dataset:\n",
    "https://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (3 marks) Use tf-idf based document representation for the task. \n",
    "\n",
    "You can use existing\n",
    "third-party libraries for document pre-processing (e.g., tokenization), however, you need to write your own code to derive tf-idf representation and compute similarity between two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1:\n",
      "This is an txt file used for practicing Python.\n",
      "The second line.\n",
      "Hello, world! --  This is the third line.\n",
      "The End. -- This is the bottom line.\n"
     ]
    }
   ],
   "source": [
    "# Read the first file\n",
    "text_file = open(\"./sample_files/textScript1.txt\", \"r\")\n",
    "text_content1 = text_file.read()\n",
    "text_file.close()\n",
    "# check the first 200 characters\n",
    "print(text_content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2: \n",
      "You are required to complete a program to find similar documents (e.g., articles, queries or questions in sentence) for a given query (e.g., an article or a sentence). \n",
      "The similarity can be defined by you, such as content similarity or emotion similarity such as sentiment. \n",
      "You can use the 20 Newsgroup dataset or any similar dataset you can find.\n"
     ]
    }
   ],
   "source": [
    "# Read the second file\n",
    "text_file = open(\"./sample_files/textScript2.txt\", \"r\")\n",
    "text_content2 = text_file.read()\n",
    "text_file.close()\n",
    "# check the first 200 characters\n",
    "print(text_content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/xinyaotian/anaconda3/lib/python3.7/site-packages (3.3)\r\n",
      "Requirement already satisfied: six in /Users/xinyaotian/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install tokenize function\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def calTermFrequency(text_content):\n",
    "    tknzr = TweetTokenizer()\n",
    "    tokenized_list = tknzr.tokenize(text_content)\n",
    "    \n",
    "    # Calculate term frequency\n",
    "    term_frequency_dict = dict()\n",
    "    for term in tokenized_list:\n",
    "        if term in term_frequency_dict.keys():\n",
    "            term_frequency_dict[term] += 1\n",
    "        else:\n",
    "            term_frequency_dict[term] = 1\n",
    "    \n",
    "    # Conduct Log operation for each term\n",
    "    log_tf_dict = dict()\n",
    "    for term in term_frequency_dict:\n",
    "        log_tf_dict[term] = (1 + log(term_frequency_dict[term], 10))\n",
    "        \n",
    "    return log_tf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLogTermFrequencyList():\n",
    "    # Need further Calsupalate of reading text_content1\n",
    "    log_tf_1 = calTermFrequency(text_content1)\n",
    "    log_tf_2 = calTermFrequency(text_content2)\n",
    "    logged_tf_list = list()\n",
    "    logged_tf_list.append(log_tf_1)\n",
    "    logged_tf_list.append(log_tf_2)\n",
    "    return logged_tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_tf_list = generateLogTermFrequencyList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'File': 1.0,\n",
       "  '1': 1.0,\n",
       "  ':': 1.0,\n",
       "  'This': 1.4771212547196624,\n",
       "  'is': 1.4771212547196624,\n",
       "  'an': 1.0,\n",
       "  'txt': 1.0,\n",
       "  'file': 1.0,\n",
       "  'used': 1.0,\n",
       "  'for': 1.0,\n",
       "  'practicing': 1.0,\n",
       "  'Python': 1.0,\n",
       "  '.': 1.6989700043360187,\n",
       "  'The': 1.3010299956639813,\n",
       "  'second': 1.0,\n",
       "  'line': 1.4771212547196624,\n",
       "  'Hello': 1.0,\n",
       "  ',': 1.0,\n",
       "  'world': 1.0,\n",
       "  '!': 1.0,\n",
       "  '-': 1.6020599913279623,\n",
       "  'the': 1.3010299956639813,\n",
       "  'third': 1.0,\n",
       "  'End': 1.0,\n",
       "  'bottom': 1.0},\n",
       " {'File': 1.0,\n",
       "  '2': 1.0,\n",
       "  ':': 1.0,\n",
       "  'You': 1.3010299956639813,\n",
       "  'are': 1.0,\n",
       "  'required': 1.0,\n",
       "  'to': 1.3010299956639813,\n",
       "  'complete': 1.0,\n",
       "  'a': 1.4771212547196624,\n",
       "  'program': 1.0,\n",
       "  'find': 1.3010299956639813,\n",
       "  'similar': 1.3010299956639813,\n",
       "  'documents': 1.0,\n",
       "  '(': 1.3010299956639813,\n",
       "  'e': 1.3010299956639813,\n",
       "  '.': 1.8450980400142567,\n",
       "  'g': 1.3010299956639813,\n",
       "  ',': 1.6020599913279623,\n",
       "  'articles': 1.0,\n",
       "  'queries': 1.0,\n",
       "  'or': 1.6020599913279623,\n",
       "  'questions': 1.0,\n",
       "  'in': 1.0,\n",
       "  'sentence': 1.3010299956639813,\n",
       "  ')': 1.3010299956639813,\n",
       "  'for': 1.0,\n",
       "  'given': 1.0,\n",
       "  'query': 1.0,\n",
       "  'an': 1.0,\n",
       "  'article': 1.0,\n",
       "  'The': 1.0,\n",
       "  'similarity': 1.4771212547196624,\n",
       "  'can': 1.4771212547196624,\n",
       "  'be': 1.0,\n",
       "  'defined': 1.0,\n",
       "  'by': 1.0,\n",
       "  'you': 1.3010299956639813,\n",
       "  'such': 1.3010299956639813,\n",
       "  'as': 1.3010299956639813,\n",
       "  'content': 1.0,\n",
       "  'emotion': 1.0,\n",
       "  'sentiment': 1.0,\n",
       "  'use': 1.0,\n",
       "  'the': 1.0,\n",
       "  '20': 1.0,\n",
       "  'Newsgroup': 1.0,\n",
       "  'dataset': 1.3010299956639813,\n",
       "  'any': 1.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_tf_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list that contains all terms appearing among all document\n",
    "def generateOverallTermList(logged_tf_list):\n",
    "    all_term_list = list()\n",
    "    for tf_dict in logged_tf_list:\n",
    "        for term in tf_dict:\n",
    "            if term in all_term_list:\n",
    "                pass\n",
    "            else:\n",
    "                all_term_list.append(term)\n",
    "    \n",
    "    return all_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['File',\n",
       " '1',\n",
       " ':',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'txt',\n",
       " 'file',\n",
       " 'used',\n",
       " 'for',\n",
       " 'practicing',\n",
       " 'Python',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'line',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'world',\n",
       " '!',\n",
       " '-',\n",
       " 'the',\n",
       " 'third',\n",
       " 'End',\n",
       " 'bottom',\n",
       " '2',\n",
       " 'You',\n",
       " 'are',\n",
       " 'required',\n",
       " 'to',\n",
       " 'complete',\n",
       " 'a',\n",
       " 'program',\n",
       " 'find',\n",
       " 'similar',\n",
       " 'documents',\n",
       " '(',\n",
       " 'e',\n",
       " 'g',\n",
       " 'articles',\n",
       " 'queries',\n",
       " 'or',\n",
       " 'questions',\n",
       " 'in',\n",
       " 'sentence',\n",
       " ')',\n",
       " 'given',\n",
       " 'query',\n",
       " 'article',\n",
       " 'similarity',\n",
       " 'can',\n",
       " 'be',\n",
       " 'defined',\n",
       " 'by',\n",
       " 'you',\n",
       " 'such',\n",
       " 'as',\n",
       " 'content',\n",
       " 'emotion',\n",
       " 'sentiment',\n",
       " 'use',\n",
       " '20',\n",
       " 'Newsgroup',\n",
       " 'dataset',\n",
       " 'any']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_term_list = generateOverallTermList(logged_tf_list)\n",
    "all_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeightMatrix(logged_tf_list, all_term_list):\n",
    "    # Initiate a empty dictionary in order to save a Word Vector of each document\n",
    "    weight_matrix_dict = dict()\n",
    "    count = 0\n",
    "    # For every document which exists in the record list\n",
    "    for file_dict in logged_tf_list:\n",
    "        word_exist_list = list()\n",
    "        # Nominate the document name\n",
    "        filename = \"Filename_\" + str(count)\n",
    "        count += 1\n",
    "        # For each word in the overall word list, \n",
    "        for word in all_term_list:\n",
    "            # if it exsits in this document, then set the value to 1\n",
    "            if word in file_dict:\n",
    "                word_exist_list.append(1)\n",
    "            # otherwise, set the value to 0, indicating that this word doesn't appear in this Doc\n",
    "            else:\n",
    "                word_exist_list.append(0)\n",
    "        \n",
    "        # Add the Word Vector of this document to the general dict\n",
    "        # In order to form a BIG 2x2 Table\n",
    "        weight_matrix_dict[filename] = word_exist_list\n",
    "    \n",
    "    return weight_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_dict = generateWeightMatrix(logged_tf_list, all_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename_0</th>\n",
       "      <th>Filename_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename_0  Filename_1\n",
       "0           1           1\n",
       "1           1           0\n",
       "2           1           1\n",
       "3           1           0\n",
       "4           1           0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weightMatrix_df = pd.DataFrame(wm_dict)\n",
    "weightMatrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function of calculating tf-idf\n",
    "def calcualetIdf(weightMatrix_df):\n",
    "    # Get the total number of columns\n",
    "    total_number_of_documents = int(weightMatrix_df.shape[1])\n",
    "    # Get the occurance times of each word\n",
    "    docFrequency_series = weightMatrix_df.sum(axis=1)\n",
    "    # Init a list storing idf \n",
    "    idf_list = list()\n",
    "    # Iterate words in order to calculate idf\n",
    "    for _, frequency in docFrequency_series.iteritems():\n",
    "        # The function of idf: log10(N/dft)\n",
    "        # In order to save memory and speed up, we only maintain 4 decimal places by round()\n",
    "        idf = round(log((total_number_of_documents * (1/frequency)), 10), 4)\n",
    "        idf_list.append(idf)\n",
    "    return idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.301, 0.0, 0.301, 0.301, 0.0, 0.301, 0.301, 0.301, 0.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_list = calcualetIdf(weightMatrix)\n",
    "idf_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a term-idf matching dict\n",
    "def generateIdfDict(idf_list, all_term_list):\n",
    "    idf_word_dict = dict()\n",
    "    i = 0\n",
    "    while i < len(all_term_list):\n",
    "        term = all_term_list[i]\n",
    "        idf_word_dict[term] = idf_list[i]\n",
    "        i += 1\n",
    "    return idf_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File': 0.0,\n",
       " '1': 0.301,\n",
       " ':': 0.0,\n",
       " 'This': 0.301,\n",
       " 'is': 0.301,\n",
       " 'an': 0.0,\n",
       " 'txt': 0.301,\n",
       " 'file': 0.301,\n",
       " 'used': 0.301,\n",
       " 'for': 0.0,\n",
       " 'practicing': 0.301,\n",
       " 'Python': 0.301,\n",
       " '.': 0.0,\n",
       " 'The': 0.0,\n",
       " 'second': 0.301,\n",
       " 'line': 0.301,\n",
       " 'Hello': 0.301,\n",
       " ',': 0.0,\n",
       " 'world': 0.301,\n",
       " '!': 0.301,\n",
       " '-': 0.301,\n",
       " 'the': 0.0,\n",
       " 'third': 0.301,\n",
       " 'End': 0.301,\n",
       " 'bottom': 0.301,\n",
       " '2': 0.301,\n",
       " 'You': 0.301,\n",
       " 'are': 0.301,\n",
       " 'required': 0.301,\n",
       " 'to': 0.301,\n",
       " 'complete': 0.301,\n",
       " 'a': 0.301,\n",
       " 'program': 0.301,\n",
       " 'find': 0.301,\n",
       " 'similar': 0.301,\n",
       " 'documents': 0.301,\n",
       " '(': 0.301,\n",
       " 'e': 0.301,\n",
       " 'g': 0.301,\n",
       " 'articles': 0.301,\n",
       " 'queries': 0.301,\n",
       " 'or': 0.301,\n",
       " 'questions': 0.301,\n",
       " 'in': 0.301,\n",
       " 'sentence': 0.301,\n",
       " ')': 0.301,\n",
       " 'given': 0.301,\n",
       " 'query': 0.301,\n",
       " 'article': 0.301,\n",
       " 'similarity': 0.301,\n",
       " 'can': 0.301,\n",
       " 'be': 0.301,\n",
       " 'defined': 0.301,\n",
       " 'by': 0.301,\n",
       " 'you': 0.301,\n",
       " 'such': 0.301,\n",
       " 'as': 0.301,\n",
       " 'content': 0.301,\n",
       " 'emotion': 0.301,\n",
       " 'sentiment': 0.301,\n",
       " 'use': 0.301,\n",
       " '20': 0.301,\n",
       " 'Newsgroup': 0.301,\n",
       " 'dataset': 0.301,\n",
       " 'any': 0.301}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_word_dict = generateIdfDict(idf_list, all_term_list)\n",
    "idf_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['File',\n",
       " '1',\n",
       " ':',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'txt',\n",
       " 'file',\n",
       " 'used',\n",
       " 'for',\n",
       " 'practicing',\n",
       " 'Python',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'line',\n",
       " '.',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'world',\n",
       " '!',\n",
       " '-',\n",
       " '-',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " '.',\n",
       " 'The',\n",
       " 'End',\n",
       " '.',\n",
       " '-',\n",
       " '-',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'line',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "term_tokenize = tknzr.tokenize(text_content1)\n",
    "term_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File': 1,\n",
       " '1': 1,\n",
       " ':': 1,\n",
       " 'This': 3,\n",
       " 'is': 3,\n",
       " 'an': 1,\n",
       " 'txt': 1,\n",
       " 'file': 1,\n",
       " 'used': 1,\n",
       " 'for': 1,\n",
       " 'practicing': 1,\n",
       " 'Python': 1,\n",
       " '.': 5,\n",
       " 'The': 2,\n",
       " 'second': 1,\n",
       " 'line': 3,\n",
       " 'Hello': 1,\n",
       " ',': 1,\n",
       " 'world': 1,\n",
       " '!': 1,\n",
       " '-': 4,\n",
       " 'the': 2,\n",
       " 'third': 1,\n",
       " 'End': 1,\n",
       " 'bottom': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency1 = dict()\n",
    "for word in term_tokenize:\n",
    "    if word in term_frequency1.keys():\n",
    "        term_frequency1[word] += 1\n",
    "    else:\n",
    "        term_frequency1[word] = 1\n",
    "\n",
    "term_frequency1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File': 1.0,\n",
       " '1': 1.0,\n",
       " ':': 1.0,\n",
       " 'This': 1.4771212547196624,\n",
       " 'is': 1.4771212547196624,\n",
       " 'an': 1.0,\n",
       " 'txt': 1.0,\n",
       " 'file': 1.0,\n",
       " 'used': 1.0,\n",
       " 'for': 1.0,\n",
       " 'practicing': 1.0,\n",
       " 'Python': 1.0,\n",
       " '.': 1.6989700043360187,\n",
       " 'The': 1.3010299956639813,\n",
       " 'second': 1.0,\n",
       " 'line': 1.4771212547196624,\n",
       " 'Hello': 1.0,\n",
       " ',': 1.0,\n",
       " 'world': 1.0,\n",
       " '!': 1.0,\n",
       " '-': 1.6020599913279623,\n",
       " 'the': 1.3010299956639813,\n",
       " 'third': 1.0,\n",
       " 'End': 1.0,\n",
       " 'bottom': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "log_tf1 = dict()\n",
    "\n",
    "for key in term_frequency1:\n",
    "    log_tf1[key] = log(term_frequency1[key], 10) + 1\n",
    "    \n",
    "log_tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (2 marks) Improve the tf-idf based method or design a better method for improved retrieval performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
