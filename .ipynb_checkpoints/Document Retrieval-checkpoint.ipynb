{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 â€“ Document Retrieval\n",
    "## Written by Xinyao Tian SID: 490085774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to complete a program to find similar documents (e.g., articles, queries or questions in sentence) for a given query (e.g., an article or a sentence). The similarity can be defined by you, such as content similarity or emotion similarity such as sentiment. You can use the 20 Newsgroup dataset or any similar dataset you can find.\n",
    "20 Newsgroup Dataset:\n",
    "https://kdd.ics.uci.edu/databases/20newsgroups/20newsgroups.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (3 marks) Use tf-idf based document representation for the task. \n",
    "\n",
    "You can use existing\n",
    "third-party libraries for document pre-processing (e.g., tokenization), however, you need to write your own code to derive tf-idf representation and compute similarity between two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from math import log\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the limitation of executing power (my old 2018 macbook...)\n",
    "# We only use 7 documents in total to represent the pricple of TF-IDF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1:\n",
      "You are not required to use this file!\n",
      "This is an txt file used for practicing Python.\n",
      "The second line.\n",
      "Hello, world! --  This is the third line.\n",
      "The End. -- This is the bottom line.\n"
     ]
    }
   ],
   "source": [
    "# First\n",
    "# Read the first file\n",
    "text_file = open(\"./sample_files/textScript1.txt\", \"r\")\n",
    "text_content1 = text_file.read()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2: \n",
      "You are required to complete a program to find similar documents (e.g., articles, queries or questions in sentence) for a given query (e.g., an article or a sentence). \n",
      "The similarity can be defined by you, such as content similarity or emotion similarity such as sentiment. \n",
      "You can use the 20 Newsgroup dataset or any similar dataset you can find.\n"
     ]
    }
   ],
   "source": [
    "# Read the second file\n",
    "text_file = open(\"./sample_files/textScript2.txt\", \"r\")\n",
    "text_content2 = text_file.read()\n",
    "text_file.close()\n",
    "# check the first 200 characters\n",
    "print(text_content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/xinyaotian/anaconda3/lib/python3.7/site-packages (3.3)\r\n",
      "Requirement already satisfied: six in /Users/xinyaotian/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install tokenize function\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Calculate Term Frequency\n",
    "def calTermFrequency(text_content):\n",
    "    tknzr = TweetTokenizer()\n",
    "    tokenized_list = tknzr.tokenize(text_content)\n",
    "    \n",
    "    # Calculate term frequency\n",
    "    term_frequency_dict = dict()\n",
    "    for term in tokenized_list:\n",
    "        if term in term_frequency_dict.keys():\n",
    "            term_frequency_dict[term] += 1\n",
    "        else:\n",
    "            term_frequency_dict[term] = 1\n",
    "    \n",
    "    # Conduct Log operation for each term\n",
    "    log_tf_dict = dict()\n",
    "    for term in term_frequency_dict:\n",
    "        log_tf_dict[term] = round((1 + log(term_frequency_dict[term], 10)), 4)\n",
    "        \n",
    "    return log_tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all term frequency dict into one huge list\n",
    "def generateLogTermFrequencyList():\n",
    "    # Need further Calsupalate of reading text_content1\n",
    "    log_tf_1 = calTermFrequency(text_content1)\n",
    "    log_tf_2 = calTermFrequency(text_content2)\n",
    "    logged_tf_list = list()\n",
    "    logged_tf_list.append(log_tf_1)\n",
    "    logged_tf_list.append(log_tf_2)\n",
    "    return logged_tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The huge list below\n",
    "logged_tf_list = generateLogTermFrequencyList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'File': 1.0,\n",
       "  '1': 1.0,\n",
       "  ':': 1.0,\n",
       "  'You': 1.0,\n",
       "  'are': 1.0,\n",
       "  'not': 1.0,\n",
       "  'required': 1.0,\n",
       "  'to': 1.0,\n",
       "  'use': 1.0,\n",
       "  'this': 1.0,\n",
       "  'file': 1.301,\n",
       "  '!': 1.301,\n",
       "  'This': 1.4771,\n",
       "  'is': 1.4771,\n",
       "  'an': 1.0,\n",
       "  'txt': 1.0,\n",
       "  'used': 1.0,\n",
       "  'for': 1.0,\n",
       "  'practicing': 1.0,\n",
       "  'Python': 1.0,\n",
       "  '.': 1.699,\n",
       "  'The': 1.301,\n",
       "  'second': 1.0,\n",
       "  'line': 1.4771,\n",
       "  'Hello': 1.0,\n",
       "  ',': 1.0,\n",
       "  'world': 1.0,\n",
       "  '-': 1.6021,\n",
       "  'the': 1.301,\n",
       "  'third': 1.0,\n",
       "  'End': 1.0,\n",
       "  'bottom': 1.0},\n",
       " {'File': 1.0,\n",
       "  '2': 1.0,\n",
       "  ':': 1.0,\n",
       "  'You': 1.301,\n",
       "  'are': 1.0,\n",
       "  'required': 1.0,\n",
       "  'to': 1.301,\n",
       "  'complete': 1.0,\n",
       "  'a': 1.4771,\n",
       "  'program': 1.0,\n",
       "  'find': 1.301,\n",
       "  'similar': 1.301,\n",
       "  'documents': 1.0,\n",
       "  '(': 1.301,\n",
       "  'e': 1.301,\n",
       "  '.': 1.8451,\n",
       "  'g': 1.301,\n",
       "  ',': 1.6021,\n",
       "  'articles': 1.0,\n",
       "  'queries': 1.0,\n",
       "  'or': 1.6021,\n",
       "  'questions': 1.0,\n",
       "  'in': 1.0,\n",
       "  'sentence': 1.301,\n",
       "  ')': 1.301,\n",
       "  'for': 1.0,\n",
       "  'given': 1.0,\n",
       "  'query': 1.0,\n",
       "  'an': 1.0,\n",
       "  'article': 1.0,\n",
       "  'The': 1.0,\n",
       "  'similarity': 1.4771,\n",
       "  'can': 1.4771,\n",
       "  'be': 1.0,\n",
       "  'defined': 1.0,\n",
       "  'by': 1.0,\n",
       "  'you': 1.301,\n",
       "  'such': 1.301,\n",
       "  'as': 1.301,\n",
       "  'content': 1.0,\n",
       "  'emotion': 1.0,\n",
       "  'sentiment': 1.0,\n",
       "  'use': 1.0,\n",
       "  'the': 1.0,\n",
       "  '20': 1.0,\n",
       "  'Newsgroup': 1.0,\n",
       "  'dataset': 1.301,\n",
       "  'any': 1.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the list\n",
    "logged_tf_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list that contains all terms appearing among all document\n",
    "def generateOverallTermList(logged_tf_list):\n",
    "    all_term_list = list()\n",
    "    for tf_dict in logged_tf_list:\n",
    "        for term in tf_dict:\n",
    "            if term in all_term_list:\n",
    "                pass\n",
    "            else:\n",
    "                all_term_list.append(term)\n",
    "    \n",
    "    return all_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['File',\n",
       " '1',\n",
       " ':',\n",
       " 'You',\n",
       " 'are',\n",
       " 'not',\n",
       " 'required',\n",
       " 'to',\n",
       " 'use',\n",
       " 'this',\n",
       " 'file',\n",
       " '!',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'txt',\n",
       " 'used',\n",
       " 'for',\n",
       " 'practicing',\n",
       " 'Python',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'line',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'world',\n",
       " '-',\n",
       " 'the',\n",
       " 'third',\n",
       " 'End',\n",
       " 'bottom',\n",
       " '2',\n",
       " 'complete',\n",
       " 'a',\n",
       " 'program',\n",
       " 'find',\n",
       " 'similar',\n",
       " 'documents',\n",
       " '(',\n",
       " 'e',\n",
       " 'g',\n",
       " 'articles',\n",
       " 'queries',\n",
       " 'or',\n",
       " 'questions',\n",
       " 'in',\n",
       " 'sentence',\n",
       " ')',\n",
       " 'given',\n",
       " 'query',\n",
       " 'article',\n",
       " 'similarity',\n",
       " 'can',\n",
       " 'be',\n",
       " 'defined',\n",
       " 'by',\n",
       " 'you',\n",
       " 'such',\n",
       " 'as',\n",
       " 'content',\n",
       " 'emotion',\n",
       " 'sentiment',\n",
       " '20',\n",
       " 'Newsgroup',\n",
       " 'dataset',\n",
       " 'any']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list with all terms who appear in all documents\n",
    "all_term_list = generateOverallTermList(logged_tf_list)\n",
    "all_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Binary Matrix which represents if a term occurs in a specific document\n",
    "def generateBinMatrix(logged_tf_list, all_term_list):\n",
    "    # Initiate a empty dictionary in order to save a Word Vector of each document\n",
    "    bin_matrix_dict = dict()\n",
    "    count = 0\n",
    "    # For every document which exists in the record list\n",
    "    for file_dict in logged_tf_list:\n",
    "        word_exist_list = list()\n",
    "        # Nominate the document name\n",
    "        filename = \"Filename_\" + str(count)\n",
    "        count += 1\n",
    "        # For each word in the overall word list, \n",
    "        for word in all_term_list:\n",
    "            # if it exsits in this document, then set the value to 1\n",
    "            if word in file_dict:\n",
    "                word_exist_list.append(1)\n",
    "            # otherwise, set the value to 0, indicating that this word doesn't appear in this Doc\n",
    "            else:\n",
    "                word_exist_list.append(0)\n",
    "        \n",
    "        # Add the Word Vector of this document to the general dict\n",
    "        # In order to form a BIG 2x2 Table\n",
    "        bin_matrix_dict[filename] = word_exist_list\n",
    "    \n",
    "    return bin_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_dict = generateBinMatrix(logged_tf_list, all_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename_0</th>\n",
       "      <th>Filename_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename_0  Filename_1\n",
       "0           1           1\n",
       "1           1           0\n",
       "2           1           1\n",
       "3           1           1\n",
       "4           1           1\n",
       "5           1           0\n",
       "6           1           1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binMatrix_df = pd.DataFrame(bin_dict)\n",
    "binMatrix_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function of calculating tf-idf\n",
    "def calcualetIdf(binMatrix_df):\n",
    "    # Get the total number of columns\n",
    "    total_number_of_documents = int(binMatrix_df.shape[1])\n",
    "    # Get the occurance times of each word\n",
    "    docFrequency_series = binMatrix_df.sum(axis=1)\n",
    "    # Init a list storing idf \n",
    "    idf_list = list()\n",
    "    # Iterate words in order to calculate idf\n",
    "    for _, frequency in docFrequency_series.iteritems():\n",
    "        # The function of idf: log10(N/dft)\n",
    "        # In order to save memory and speed up, we only maintain 4 decimal places by round()\n",
    "        idf = round(log((total_number_of_documents * (1/frequency)), 10), 4)\n",
    "        idf_list.append(idf)\n",
    "    return idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.301, 0.0, 0.0, 0.0, 0.301, 0.0, 0.0, 0.0, 0.301]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_list = calcualetIdf(binMatrix_df)\n",
    "idf_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a term-idf matching dict\n",
    "def generateIdfDict(idf_list, all_term_list):\n",
    "    idf_word_dict = dict()\n",
    "    i = 0\n",
    "    while i < len(all_term_list):\n",
    "        term = all_term_list[i]\n",
    "        idf_word_dict[term] = idf_list[i]\n",
    "        i += 1\n",
    "    return idf_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_word_dict = generateIdfDict(idf_list, all_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Tf-idf\n",
    "def calculateWeightMatrix(idf_word_dict, logged_tf_list, all_term_list):\n",
    "    overall_list = list()\n",
    "    count = 0\n",
    "    # match the term in overall-term with each Doc\n",
    "    for doc in logged_tf_list:\n",
    "        tf_idf_list = list()\n",
    "        for term in all_term_list:\n",
    "            if term in doc.keys():\n",
    "                tfIdf = round( (idf_word_dict[term] * doc[term]), 4)\n",
    "                tf_idf_list.append(tfIdf)\n",
    "            else:\n",
    "                tf_idf_list.append(0.0)\n",
    "        \n",
    "        # overall_list.append({str(count):tf_idf_list})\n",
    "        overall_list.append(tf_idf_list)\n",
    "        count += 1\n",
    "    return overall_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This</th>\n",
       "      <td>0.4446</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.4446</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>practicing</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.4446</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documents</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articles</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queries</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>given</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defined</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newsgroup</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0       1\n",
       "File        0.0000  0.0000\n",
       "1           0.3010  0.0000\n",
       ":           0.0000  0.0000\n",
       "You         0.0000  0.0000\n",
       "are         0.0000  0.0000\n",
       "not         0.3010  0.0000\n",
       "required    0.0000  0.0000\n",
       "to          0.0000  0.0000\n",
       "use         0.0000  0.0000\n",
       "this        0.3010  0.0000\n",
       "file        0.3916  0.0000\n",
       "!           0.3916  0.0000\n",
       "This        0.4446  0.0000\n",
       "is          0.4446  0.0000\n",
       "an          0.0000  0.0000\n",
       "txt         0.3010  0.0000\n",
       "used        0.3010  0.0000\n",
       "for         0.0000  0.0000\n",
       "practicing  0.3010  0.0000\n",
       "Python      0.3010  0.0000\n",
       ".           0.0000  0.0000\n",
       "The         0.0000  0.0000\n",
       "second      0.3010  0.0000\n",
       "line        0.4446  0.0000\n",
       "Hello       0.3010  0.0000\n",
       ",           0.0000  0.0000\n",
       "world       0.3010  0.0000\n",
       "-           0.4822  0.0000\n",
       "the         0.0000  0.0000\n",
       "third       0.3010  0.0000\n",
       "...            ...     ...\n",
       "similar     0.0000  0.3916\n",
       "documents   0.0000  0.3010\n",
       "(           0.0000  0.3916\n",
       "e           0.0000  0.3916\n",
       "g           0.0000  0.3916\n",
       "articles    0.0000  0.3010\n",
       "queries     0.0000  0.3010\n",
       "or          0.0000  0.4822\n",
       "questions   0.0000  0.3010\n",
       "in          0.0000  0.3010\n",
       "sentence    0.0000  0.3916\n",
       ")           0.0000  0.3916\n",
       "given       0.0000  0.3010\n",
       "query       0.0000  0.3010\n",
       "article     0.0000  0.3010\n",
       "similarity  0.0000  0.4446\n",
       "can         0.0000  0.4446\n",
       "be          0.0000  0.3010\n",
       "defined     0.0000  0.3010\n",
       "by          0.0000  0.3010\n",
       "you         0.0000  0.3916\n",
       "such        0.0000  0.3916\n",
       "as          0.0000  0.3916\n",
       "content     0.0000  0.3010\n",
       "emotion     0.0000  0.3010\n",
       "sentiment   0.0000  0.3010\n",
       "20          0.0000  0.3010\n",
       "Newsgroup   0.0000  0.3010\n",
       "dataset     0.0000  0.3916\n",
       "any         0.0000  0.3010\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix = calculateWeightMatrix(idf_word_dict, logged_tf_list, all_term_list)\n",
    "weight_matrix_df = pd.DataFrame(weight_matrix).transpose()\n",
    "weight_matrix_df.index = all_term_list\n",
    "weight_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate norm\n",
    "def calculateNorm(term_vector):\n",
    "    sum_of_value = 0\n",
    "    for _, value in term_vector.iteritems():\n",
    "        sum_of_value += value **2\n",
    "    return round(sqrt(sum_of_value), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weight_matrix_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate dotProduct\n",
    "def calculateDotProduct(term_vector1, term_vector2):\n",
    "    dotProduct = np.dot(term_vector1.values, term_vector2.values)\n",
    "    return round(dotProduct, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Cosine similarity\n",
    "def computeCosSimilarity(term_vector1, term_vector2):\n",
    "    norm0 = calculateNorm(term_vector1)\n",
    "    norm1 = calculateNorm(term_vector2)\n",
    "    dotProduct = calculateDotProduct(term_vector1, term_vector2)\n",
    "    cosine_value = dotProduct / ((norm0) * (norm1))\n",
    "    return round(cosine_value, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSimilarity = computeCosSimilarity(weight_matrix_df[0], weight_matrix_df[1])\n",
    "cosSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (2 marks) Improve the tf-idf based method or design a better method for improved retrieval performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
